{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed throughout the notebook\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40e5e8",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d4396",
   "metadata": {},
   "source": [
    "### Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mymatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6acea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a range in numpy format. start, end, steps\n",
    "np.arange(0, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52976d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an array of zeros. row, columns\n",
    "np.zeros((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# over x range, give me y number with equal intervals\n",
    "np.linspace(0, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity matrix\n",
    "np.eye(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7f983",
   "metadata": {},
   "source": [
    "### Random NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an array of n numbers between 0 and 1.\n",
    "np.random.rand(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an array of n numbers between 0 and 1. rows, columns, n numbers\n",
    "np.random.rand(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns values from a normal distribution with a mean 0 and a variance of 1\n",
    "np.random.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d53d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns values from a normal distribution with a mean 0 and a variance of 1. rows, columns\n",
    "np.random.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from x to y, return z numbers\n",
    "np.random.randint(0, 101, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from x to y, return z numbers in the sahpe of rows and columns\n",
    "np.random.randint(0, 101, (5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19828a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a random seed\n",
    "np.random.seed(42)\n",
    "np.random.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating array to show methods\n",
    "arr = np.arange(0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the array. cannot rearrange if elements don't fit into the shape\n",
    "arr.reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an array\n",
    "ranarr = np.random.randint(0,101,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76903df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding max and min of the array\n",
    "print(ranarr.max())\n",
    "print(ranarr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the index of the max\n",
    "ranarr.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253298e7",
   "metadata": {},
   "source": [
    "### NP indexing and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7204798",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(0,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e88e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing a specific value by index\n",
    "arr[0]\n",
    "\n",
    "# grabbing a range in the array 0 to 5\n",
    "arr[:5]\n",
    "\n",
    "# grabbing 5 to end\n",
    "arr[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a range and change all numbers to something (can only be done with numpy array)\n",
    "arr[:5] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with numpy, making changes to a slice of an array saves the changes to the original array. you must create a copy\n",
    "# in order to have no changes done to the original array\n",
    "arr_copy = arr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a044ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing 2D\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2d[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a40aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing 2d other method. value of row x and column y\n",
    "arr_2d[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing rows and or columns\n",
    "\n",
    "# gives rows from index 0 to 2\n",
    "arr_2d[:2]\n",
    "\n",
    "# from row 0 to row 2 not inclusive and from column 1 to final column\n",
    "arr_2d[:2, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.arange(0,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba616e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing based on conditions\n",
    "# returns the indexes where the condition is true\n",
    "condition = array > 5\n",
    "array[condition]\n",
    "\n",
    "# same as\n",
    "array[array > 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e9d81",
   "metadata": {},
   "source": [
    "### Numpy operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.arange(0,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different operations of array. using an operation on array will do it to every element of the array\n",
    "print(array - 2)\n",
    "print(array + 3)\n",
    "print(array * 2)\n",
    "\n",
    "# you can operate on two arrays\n",
    "print(array - array)\n",
    "print(array + array)\n",
    "print(array * array)\n",
    "\n",
    "# find the square root\n",
    "print(np.sqrt(array))\n",
    "\n",
    "# other examples\n",
    "print(array.mean())\n",
    "print(array.max())\n",
    "print(array.std())\n",
    "print(array.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18856203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix of arrays\n",
    "array2d = np.arange(0, 25).reshape(5, 5)\n",
    "array2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14282b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the columns. axis 1 would be by row\n",
    "print(array2d.sum(axis=0))\n",
    "print(array2d.sum(axis=1))\n",
    "\n",
    "# sum of everything in the array\n",
    "print(array2d.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec0bd9",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16a2a7",
   "metadata": {},
   "source": [
    "### Pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f82e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with indexes that can be string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "myindex = ['USA', 'CANADA', 'MEXICO']\n",
    "mydata = [1776, 1867, 1821]\n",
    "myser = pd.Series(data=mydata, index=myindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ae67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can take a doctionary and turn it into a pandas series. it'll turn it into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cae4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imaginary Sales Data for 1st and 2nd Quarters for Global Company\n",
    "q1 = {'Japan': 80, 'China': 450, 'India': 200, 'USA': 250}\n",
    "q2 = {'Brazil': 100,'China': 500, 'India': 210,'USA': 260}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the dictionaries into series\n",
    "salesq1 = pd.Series(q1)\n",
    "salesq2 = pd.Series(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808fe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the keys for the series\n",
    "salesq1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b156ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations on the series. doing same thing to every value\n",
    "salesq1 / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding both series together even if some values aren't present in both\n",
    "salesq1.add(salesq2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b7a96",
   "metadata": {},
   "source": [
    "### Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe is basically a table\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data for datafram\n",
    "np.random.seed(101)\n",
    "mydata = np.random.randint(0, 101, (4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd25a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe\n",
    "myindex = ['CA', 'NY', 'AZ', 'TX']\n",
    "mycolumns = ['Jan', 'Feb', 'Mar']\n",
    "df = pd.DataFrame(mydata, myindex, mycolumns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bec475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in a csv file\n",
    "myfile = \"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/tips.csv\"\n",
    "df = pd.read_csv(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575784e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts the amount of instances in a column\n",
    "df.value_counts(['sex'])\n",
    "\n",
    "# column names\n",
    "df.columns\n",
    "\n",
    "# vlaues for indexes\n",
    "df.index\n",
    "\n",
    "# head shows the first x rows. default is 5\n",
    "df.head(10)\n",
    "\n",
    "# tail is the oppsite of head\n",
    "df.tail()\n",
    "\n",
    "# info of the table\n",
    "df.info()\n",
    "\n",
    "# gives simple statistical information for columns that are numbers\n",
    "df.describe()\n",
    "\n",
    "# changes columns with indexes. might be easier to read\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13045690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab65a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing and selecting from the dataframe. selecting multiple columns\n",
    "df[['total_bill', 'tip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3213b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column in the dataframe\n",
    "df['percent_tip'] = ((df['tip']/df['total_bill'])*100).round(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8274dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows or columns. axis 0 is row and 1 is column. default is 0\n",
    "# DOING THIS TYPE OF OPERATION IS NOT DONE IN PLACE. YOU NEED TO SET IT TO NEW OR OLD DF\n",
    "df = df.drop('percent_tip',axis=1)\n",
    "\n",
    "# or set inplace to true\n",
    "df.drop('percent_tip',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1627bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a column as the index. doesn't occur in place\n",
    "df = df.set_index('Payment ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0923b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the index as a column. resetting\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing rows by number index\n",
    "df.iloc[0]\n",
    "\n",
    "# grabbing rows by named index\n",
    "df.loc['Sun2959']\n",
    "\n",
    "# grabbing multiple rows with integer index. slicing\n",
    "df.iloc[0:3]\n",
    "\n",
    "# grabbing multiple rows by index labels\n",
    "df.loc[['Sun2959', 'Sun5260']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with labeled indexes requires the label to drop\n",
    "df = df.drop('Sun2959')\n",
    "df.head()\n",
    "\n",
    "# removing mutliple rows by slicing filtering\n",
    "df = df.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding rows. keeps the same index. make sure you're not duplicating the row in future\n",
    "row = df.iloc[0]\n",
    "df = df.append(row)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe07542",
   "metadata": {},
   "source": [
    "### Conditional filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for where values of a column meet a condition\n",
    "df[df['total_bill'] > 40]\n",
    "\n",
    "# multiple conditions (and &) (or |) for pandas. regullar python is and + or. AND\n",
    "df[(df['total_bill']>40) & (df['sex']=='Male')]\n",
    "\n",
    "# OR\n",
    "df[(df['total_bill']>30) | (df['sex']=='Male')]\n",
    "\n",
    "# isin. faster than using a bunch of ORs\n",
    "df[df['day'].isin(['Sat', 'Sun', 'Mon'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1edba8",
   "metadata": {},
   "source": [
    "### Apply method on single columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for what we want to do\n",
    "def last_four(num):\n",
    "    return str(num)[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply it to all the values in a column\n",
    "df['last4'] = df['CC Number'].apply(last_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b12774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp(price):\n",
    "    if price < 10:\n",
    "        return '$'\n",
    "    elif price >= 10 and price <30: # we use and instead of & because it's regular python here\n",
    "        return '$$'\n",
    "    else:\n",
    "        return '$$$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d48d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yelp'] = df['total_bill'].apply(yelp)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c436f",
   "metadata": {},
   "source": [
    "### Apply method with multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f60c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in a csv file\n",
    "myfile = \"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/tips.csv\"\n",
    "df = pd.read_csv(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b53663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bill'].apply(lambda bill: bill*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1619139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(total_bill,tip):\n",
    "    if tip / total_bill > 0.25:\n",
    "        return 'generous'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the above function as a lambda function\n",
    "# applying the function to multiple columns\n",
    "df['quality'] = df[['total_bill', 'tip']].apply(lambda df: quality(df['total_bill'],df['tip']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize method. applying a function to multiple columns. vectorize is faster than lambda\n",
    "df['quality'] = np.vectorize(quality)(df['total_bill'], df['tip'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6296c",
   "metadata": {},
   "source": [
    "### Sattistical information , sorting, and other useful methods for dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceeef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical info of columns\n",
    "df.describe()\n",
    "\n",
    "# sorting dataframe by a column's values. also multiple columns\n",
    "df.sort_values(['tip','size'], ascending=True)\n",
    "\n",
    "# max value. same for min()\n",
    "df['total_bill'].max()\n",
    "\n",
    "# index of max. same for idxmin()\n",
    "df['total_bill'].idxmax()\n",
    "\n",
    "# correlation check. only works with numeric columns\n",
    "df.corr()\n",
    "\n",
    "# counting amount of values in a column\n",
    "df['sex'].value_counts()\n",
    "\n",
    "# return the unique values\n",
    "df['day'].unique()\n",
    "\n",
    "# return the number of unique values\n",
    "df['day'].nunique()\n",
    "\n",
    "# replace method. only one value is being replaced\n",
    "df['sex'].replace('Male', 'M')\n",
    "\n",
    "# replace multiple values at once\n",
    "df['sex'].replace(['Male', 'Female'], ['M', 'F'])\n",
    "\n",
    "# replacing with mapping\n",
    "mymap = {'Female':'F', 'Male':'M'}\n",
    "df['sex'].map(mymap)\n",
    "\n",
    "# dealing with duplicated rows. returns true for the very first instance that is duplicated\n",
    "df.duplicated()\n",
    "\n",
    "# dropping duplicate rows\n",
    "df.drop_duplicates()\n",
    "\n",
    "# finding values between two numbers\n",
    "df[df['total_bill'].between(10,20, inclusive=True)]\n",
    "\n",
    "# finding the n rows with the largst value of a column\n",
    "df.nlargest(10, 'tip')\n",
    "\n",
    "# same as before but smallest\n",
    "df.nsmallest(10, 'tip')\n",
    "\n",
    "# taking a sample of a dataframe by number of rows\n",
    "df.sample(5)\n",
    "\n",
    "# sample by fraction of the dataframe\n",
    "df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97963b0f",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# loading in a csv file\n",
    "myfile = \"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/movie_scores.csv\"\n",
    "df = pd.read_csv(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ebc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a True False dataframe of what's empty or not\n",
    "df.isnull()\n",
    "\n",
    "# opposite of previous method\n",
    "df.notnull()\n",
    "\n",
    "# getting back the rows where column rows are not null\n",
    "df[df['pre_movie_score'].notnull()]\n",
    "\n",
    "# two conditions\n",
    "df[(df['pre_movie_score'].isnull()) & (df['first_name'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37000ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the NA data. drops rows where any cell is missing a value. axis 1 is columns and 0 is rows\n",
    "df.dropna(axis=0)\n",
    "\n",
    "# dropping the NA data where all cells are missing\n",
    "df.dropna(how='all')\n",
    "\n",
    "# dropping requiring that many non NA values\n",
    "df.dropna(thresh=4)\n",
    "\n",
    "# drop the rows where there is an NA in the subset\n",
    "df.dropna(subset=['last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72cc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in NAs. fills in every NA value with your choice\n",
    "df.fillna('String')\n",
    "\n",
    "# filling in NA of a specific column with the desired value\n",
    "df['pre_movie_score'] = df['pre_movie_score'].fillna(0)\n",
    "df\n",
    "\n",
    "# fill in with a function\n",
    "df['pre_movie_score'].fillna(df['pre_movie_score'].mean())\n",
    "\n",
    "# fill with the averages of each column. things that don't have an average value will keep the NAs\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc2e08",
   "metadata": {},
   "source": [
    "### Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# loading in a csv file\n",
    "myfile = \"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/mpg.csv\"\n",
    "df = pd.read_csv(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86299dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by a column's values and finding the mean. also grab only the mpg column\n",
    "df.groupby('model_year').mean()['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by multiple columns\n",
    "year_cyl = df.groupby(['model_year', 'cylinders']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistical info of the df when grouped by a column\n",
    "df.groupby('model_year').describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c08f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab by index\n",
    "year_cyl.loc[[70,82]]\n",
    "\n",
    "# grabbing with double index\n",
    "year_cyl.loc[[(70,4), (70,6)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e148a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing from multilevel indexes. CROSS SECTION\n",
    "year_cyl.xs(key=70, level='cylinders')\n",
    "# grabbing only 4 cylinder cars from every year\n",
    "year_cyl.xs(key=4, level='cylinders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swaps index levels. year with cylinders\n",
    "year_cyl.swaplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41338d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort multilevel indexes\n",
    "year_cyl.sort_index(level='model_year', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bf3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize aggregate functions per column !!!\n",
    "df.agg({'mpg':['max', 'mean'], 'weight':['mean','std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e1649",
   "metadata": {},
   "source": [
    "### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# loading in a csv file\n",
    "myfile = \"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/mpg.csv\"\n",
    "df1 = pd.read_csv(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation works when the tables have the exact same format\n",
    "data_one = {'A': ['A0', 'A1', 'A2', 'A3'],'B': ['B0', 'B1', 'B2', 'B3']}\n",
    "data_two = {'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1', 'D2', 'D3']}\n",
    "one = pd.DataFrame(data_one)\n",
    "two = pd.DataFrame(data_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate by column. keep same rows but add columns\n",
    "# axis 0 will concatenate by row\n",
    "pd.concat([one, two], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae78d16",
   "metadata": {},
   "source": [
    "### Inner merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7451da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "registrations = pd.DataFrame({'reg_id':[1,2,3,4],'name':['Andrew','Bobo','Claire','David']})\n",
    "logins = pd.DataFrame({'log_id':[1,2,3,4],'name':['Xavier','Andrew','Yolanda','Bobo']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(registrations, logins, how = 'inner', on = 'name' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f43da7",
   "metadata": {},
   "source": [
    "### Left and right merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left merge merges and keeps everything from the table on the left\n",
    "pd.merge(registrations, logins, how = 'left', on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# right merge merges and keeps everything from the table on the right\n",
    "pd.merge(registrations, logins, how='right', on='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ca293",
   "metadata": {},
   "source": [
    "### Outer merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bf1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer merge merges both tables without having to match. those that match don't get duplicated\n",
    "pd.merge(registrations, logins, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c0cfa",
   "metadata": {},
   "source": [
    "### Text methods for string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d61684",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = 'jose@email.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf30a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on value but removes value\n",
    "email.split('@')\n",
    "\n",
    "# checking if it is a type\n",
    "email.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.Series(['andrew','bobo','claire','david','4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn everything into capital letters\n",
    "names.str.upper()\n",
    "\n",
    "# checking if it's a type\n",
    "names.str.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f98e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the series into a df\n",
    "tech_finance = ['GOOG,APPL,AMZN','JPM,BAC,GS']\n",
    "tickers = pd.Series(tech_finance)\n",
    "tickers.str.split(',',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stringing together string calls\n",
    "messy_names = pd.Series([\"andrew  \",\"bo;bo\",\"  claire  \"])\n",
    "messy_names.str.replace(\";\",\"\").str.strip().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3522c",
   "metadata": {},
   "source": [
    "### Time methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To illustrate the order of arguments\n",
    "my_year = 2017\n",
    "my_month = 1\n",
    "my_day = 2\n",
    "my_hour = 13\n",
    "my_minute = 30\n",
    "my_second = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# January 2nd, 2017 at 13:30:15\n",
    "my_date_time = datetime(my_year,my_month,my_day,my_hour,my_minute,my_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "myser = pd.Series(['Nov 3, 2000', '2000-01-01', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the series objet into datetime\n",
    "pd.to_datetime(myser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6635cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10th of Dec OR 12th of October?\n",
    "# We may need to tell pandas\n",
    "euro_date = '10-12-2000'\n",
    "pd.to_datetime(euro_date,dayfirst=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning weird formats into dates\n",
    "style_date = '12--Dec--2000'\n",
    "pd.to_datetime(style_date, format='%d--%b--%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62642390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another weird format\n",
    "strange_date = '12th of Dec 2000'\n",
    "pd.to_datetime(strange_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a csv file\n",
    "sales = pd.read_csv(\"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/RetailSales_BeerWineLiquor.csv\")\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839bed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the column into datetime objects\n",
    "sales['DATE'] = pd.to_datetime(sales['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a csv file and parse date at the same time\n",
    "# read in a csv file\n",
    "sales = pd.read_csv(\"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/RetailSales_BeerWineLiquor.csv\", parse_dates=[0])\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly Means. group by year and get the mean\n",
    "# RESAMPLE\n",
    "sales = sales.set_index(\"DATE\")\n",
    "sales.resample(rule='A').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70536b2c",
   "metadata": {},
   "source": [
    "### CSV input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1aaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header = None would assume the first row is not a header\n",
    "# make one of the columns an index. set index to a or index_col=0 to set the first column to the index\n",
    "df = pd.read_csv(\"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b422573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=True would use the current index. Flase would not\n",
    "df.to_csv('new_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f5236",
   "metadata": {},
   "source": [
    "### HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427aeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas can do it at times. when it can't, use beautiful soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599742f",
   "metadata": {},
   "source": [
    "### Excel files input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41878e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you set the sheet name to None, you'll get a dictionary with all the sheets\n",
    "# for the dictionary, the key is the sheet name and the value is a dataframe\n",
    "xl = pd.read_excel(\"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/my_excel_file.xlsx\", sheet_name='First_Sheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711094b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing out to an excel file\n",
    "xl.to_excel('excel.xlsx', sheet_name='new')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6622843",
   "metadata": {},
   "source": [
    "### SQL input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54823047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a temporary sql database in my RAM\n",
    "temp_db = create_engine('sqlite:///:memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02055d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "df = pd.DataFrame(data=np.random.randint(low=0, high=100, size=(4,4)), columns=['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a76dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the datafrane into a sql table with the engine we created\n",
    "df.to_sql(name='new_table', con=temp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the table from th sql database\n",
    "new_df = pd.read_sql(sql='new_table', con=temp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a sql query to read the database\n",
    "pd.read_sql_query(sql=\"SELECT a, c FROM new_table\", con=temp_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b975df",
   "metadata": {},
   "source": [
    "### Pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e101f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95784edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/eduardoarmenta/Desktop/LEARN/UDEMY/Python Data Science/UNZIP_FOR_NOTEBOOKS_FINAL/03-Pandas/Sales_Funnel_CRM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot tables like Excel\n",
    "licenses = df[['Company','Product','Licenses' ]]\n",
    "licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the pivot table\n",
    "pd.pivot(data=licenses, index='Company', columns='Product', values='Licenses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9113d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice Account Number sum() doesn't make sense to keep/use\n",
    "pd.pivot_table(df,index=\"Company\",aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either grab the columns\n",
    "pd.pivot_table(df,index=\"Company\",aggfunc='sum')[['Licenses','Sale Price']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
